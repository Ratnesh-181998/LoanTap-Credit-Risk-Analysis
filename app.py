import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from io import StringIO
import logging
import sys
import warnings
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve
from category_encoders import TargetEncoder
from imblearn.over_sampling import SMOTE

warnings.filterwarnings('ignore')

# Configure Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("app.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

st.set_page_config(
    page_title="LoanTap-Credit-Risk-Analysis", 
    layout="wide",
    page_icon="üí∞",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    .block-container {
        background: rgba(17, 24, 39, 0.95);
        border-radius: 20px;
        padding: 2rem;
        box-shadow: 0 10px 40px rgba(0,0,0,0.5);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.1);
    }
    h1 {
        background: linear-gradient(135deg, #a78bfa 0%, #f472b6 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem !important;
        font-weight: 800 !important;
        text-align: center;
        margin-bottom: 1rem;
        animation: fadeInDown 1s ease-in-out;
    }
    h2 { color: #f3f4f6 !important; border-bottom: 3px solid #764ba2; padding-bottom: 0.5rem; margin-top: 2rem; font-weight: 700 !important; }
    h3 { color: #e5e7eb !important; margin-top: 1.5rem; font-weight: 600 !important; }
    p, li, span, div { color: #d1d5db; }
    [data-testid="stMetricValue"] {
        background: linear-gradient(135deg, #a78bfa 0%, #f472b6 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem !important;
        font-weight: 800 !important;
        text-align: center;
        margin-bottom: 1rem;
        animation: fadeInDown 1s ease-in-out;
    }
    [data-testid="stMetricLabel"] { color: #9ca3af !important; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; background-color: transparent; }
    .stTabs [data-baseweb="tab"] {
        background-color: rgba(102, 126, 234, 0.1); color: #667eea; border-radius: 8px; padding: 10px 20px; font-weight: 600; transition: all 0.3s ease; border: 1px solid rgba(102, 126, 234, 0.2);
    }
    .stTabs [data-baseweb="tab"]:hover { background-color: rgba(102, 126, 234, 0.2); transform: translateY(-2px); }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important; color: white !important; box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    [data-testid="stSidebar"] { background: linear-gradient(180deg, #667eea 0%, #764ba2 100%); color: white; }
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; padding: 0.75rem 2rem; font-weight: 600; box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
    }
    .stButton > button:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6); }
    @keyframes fadeInDown { from { opacity: 0; transform: translateY(-20px); } to { opacity: 1; transform: translateY(0); } }
</style>
""", unsafe_allow_html=True)

# Title
st.markdown("""
<div style='position: fixed; top: 3.5rem; right: 1.5rem; z-index: 9999;'>
    <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                border-radius: 20px; padding: 0.5rem 1rem; 
                box-shadow: 0 4px 15px rgba(0,0,0,0.3);'>
        <span style='color: white; font-weight: 600; font-size: 0.9rem; letter-spacing: 1px;'>
            By RATNESH SINGH
        </span>
    </div>
</div>
<div style='text-align: center; padding: 1rem 0;'>
    <h1 style='font-size: 3.5rem; margin-bottom: 0;'>üí∞ LoanTap-Credit-Risk-Analysis</h1>
    <p style='font-size: 1.2rem; color: #a78bfa; font-weight: 500; margin-top: 0.5rem;'>üöÄ Creditworthiness Assessment & Underwriting</p>
</div>
""", unsafe_allow_html=True)

# Feature Cards
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.markdown("""<div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 15px; text-align: center; color: white; box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);'><h2 style='color: white; border: none; margin: 0; font-size: 2.5rem;'>üìä</h2><h3 style='color: white; margin: 0.5rem 0;'>EDA</h3><p style='margin: 0; font-size: 0.9rem;'>Data Exploration</p></div>""", unsafe_allow_html=True)
with col2:
    st.markdown("""<div style='background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); padding: 1.5rem; border-radius: 15px; text-align: center; color: white; box-shadow: 0 4px 15px rgba(240, 147, 251, 0.4);'><h2 style='color: white; border: none; margin: 0; font-size: 2.5rem;'>üîß</h2><h3 style='color: white; margin: 0.5rem 0;'>Processing</h3><p style='margin: 0; font-size: 0.9rem;'>Cleaning & Encoding</p></div>""", unsafe_allow_html=True)
with col3:
    st.markdown("""<div style='background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); padding: 1.5rem; border-radius: 15px; text-align: center; color: white; box-shadow: 0 4px 15px rgba(17, 153, 142, 0.4);'><h2 style='color: white; border: none; margin: 0; font-size: 2.5rem;'>ü§ñ</h2><h3 style='color: white; margin: 0.5rem 0;'>Modeling</h3><p style='margin: 0; font-size: 0.9rem;'>Logistic Regression</p></div>""", unsafe_allow_html=True)
with col4:
    st.markdown("""<div style='background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); padding: 1.5rem; border-radius: 15px; text-align: center; color: white; box-shadow: 0 4px 15px rgba(250, 112, 154, 0.4);'><h2 style='color: white; border: none; margin: 0; font-size: 2.5rem;'>üí°</h2><h3 style='color: white; margin: 0.5rem 0;'>Insights</h3><p style='margin: 0; font-size: 0.9rem;'>Business Recommendations</p></div>""", unsafe_allow_html=True)
st.markdown("<br>", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.markdown("## üìë Table of Contents")
    st.markdown("---")
    st.markdown("""
    ### üìä Context & Problem
    - **Context:** LoanTap's underwriting layer.
    - **Problem:** Determine creditworthiness.
    - **Goal:** Minimize NPA (Non-Performing Assets).
    
    ### üîç Data Analysis
    - **Data Dictionary:** Understanding features.
    - **EDA:** Univariate & Bivariate analysis.
    - **Missing Values:** Handling nulls.
    - **Outliers:** Detection & treatment.
    
    ### ‚öôÔ∏è Feature Engineering
    - **Target Encoding:** Handling categorical vars.
    - **Scaling:** StandardScaler.
    - **Balancing:** SMOTE for class imbalance.
    
    ### ü§ñ Model Building
    - **Logistic Regression**
    - **Decision Tree**
    - **Random Forest**
    - **Evaluation:** ROC-AUC, Precision-Recall.
    
    ### üí° Insights
    - **Risk Factors:** Grades, Home Ownership, etc.
    - **Recommendations:** Threshold tuning.
    """)
    st.markdown("---")
    st.markdown("### üìö Resources")
    st.markdown("""- [Scikit-learn](https://scikit-learn.org)\n- [LoanTap Case Study](https://www.scaler.com)""")

# Helper Functions
@st.cache_data
def load_data():
    logger.info("Loading data...")
    try:
        # Try loading txt first as per notebook
        df = pd.read_csv("logistic_regression.txt")
        
        # Sample for faster processing (100k rows is sufficient for analysis)
        if len(df) > 100000:
            df = df.sample(n=100000, random_state=42)
            logger.info(f"Sampled data to 100,000 rows for faster processing")
        
        logger.info("Data loaded successfully.")
        return df
    except Exception as e:
        logger.error(f"Error loading data: {e}")
        st.error(f"Error loading data: {e}")
        return None

@st.cache_data
def preprocess_data(df):
    logger.info("Preprocessing data...")
    data = df.copy()
    
    # Missing Value Treatment
    from sklearn.impute import SimpleImputer
    Imputer = SimpleImputer(strategy="most_frequent")
    data["mort_acc"] = Imputer.fit_transform(data["mort_acc"].values.reshape(-1,1))
    data.dropna(inplace=True)
    
    # Feature Engineering from Notebook
    # Calculate loan tenure in months (using days and converting to approximate months)
    try:
        data["Loan_Tenure"] = ((pd.to_datetime(data["issue_d"]) - pd.to_datetime(data["earliest_cr_line"])).dt.days / 30.44)
    except:
        # If date conversion fails, skip this feature
        pass
    
    try:
        data["address"] = data["address"].str.split().apply(lambda x:x[-1] if isinstance(x, list) and len(x) > 0 else "")
        data["pin_code"] = data["address"]
    except:
        pass
    
    # Dropping columns
    data.drop(["title","issue_d","earliest_cr_line","initial_list_status", "address", "pin_code", "Loan_Tenure"], axis=1, inplace=True, errors='ignore')
    
    # Target Encoding Prep
    data["loan_status"].replace({"Fully Paid":0, "Charged Off": 1}, inplace=True)
    
    return data

# Main App Logic
df_raw = load_data()

if df_raw is not None:
    # Auto-run preprocessing on first load
    if 'df_processed' not in st.session_state:
        progress_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            progress_text.text("üîÑ Step 1/2: Preprocessing data...")
            progress_bar.progress(25)
            
            df_processed = preprocess_data(df_raw)
            st.session_state['df_processed'] = df_processed
            logger.info("Preprocessing completed successfully")
            
            progress_bar.progress(100)
            progress_text.text("‚úÖ Data ready!")
            
            # Clear progress indicators after a moment
            import time
            time.sleep(1)
            progress_text.empty()
            progress_bar.empty()
            
        except Exception as e:
            logger.error(f"Preprocessing error: {e}")
            st.error(f"Preprocessing failed: {e}")
            progress_text.empty()
            progress_bar.empty()
    
    tabs = st.tabs(["üìä Data", "üîç EDA", "üîß Preprocessing", "ü§ñ Modeling", "üí° Insights", "üìö Complete Analysis", "üìù Logs"])
    
    # TAB 1: Data
    with tabs[0]:
        st.header("üìä Data Overview")
        
        # Interactive metrics with animation
        m1, m2, m3, m4 = st.columns(4)
        with m1: 
            st.metric("Total Loans", f"{len(df_raw):,}", help="Total number of loan records in dataset")
        with m2: 
            st.metric("Features", f"{df_raw.shape[1]}", help="Number of features/columns")
        with m3: 
            st.metric("Fully Paid", f"{len(df_raw[df_raw['loan_status']=='Fully Paid']):,}", 
                     delta=f"{len(df_raw[df_raw['loan_status']=='Fully Paid'])/len(df_raw)*100:.1f}%",
                     delta_color="normal")
        with m4: 
            st.metric("Charged Off", f"{len(df_raw[df_raw['loan_status']=='Charged Off']):,}",
                     delta=f"{len(df_raw[df_raw['loan_status']=='Charged Off'])/len(df_raw)*100:.1f}%",
                     delta_color="inverse")
        
        st.markdown("---")
        
        # Interactive Data Explorer
        st.subheader("üîç Interactive Data Explorer")
        
        col_explorer1, col_explorer2 = st.columns([2, 1])
        
        with col_explorer1:
            # Column selector
            all_columns = df_raw.columns.tolist()
            selected_columns = st.multiselect(
                "Select columns to display",
                options=all_columns,
                default=all_columns[:10] if len(all_columns) > 10 else all_columns
            )
        
        with col_explorer2:
            # Number of rows to display
            num_rows = st.slider("Number of rows to display", min_value=5, max_value=100, value=10, step=5)
        
        # Search functionality
        search_col = st.selectbox("Search in column", options=all_columns)
        search_term = st.text_input(f"Search for value in '{search_col}'")
        
        # Apply search filter
        if search_term:
            display_df = df_raw[df_raw[search_col].astype(str).str.contains(search_term, case=False, na=False)]
            st.info(f"Found {len(display_df)} matching records")
        else:
            display_df = df_raw
        
        # Display filtered data
        if selected_columns:
            st.dataframe(
                display_df[selected_columns].head(num_rows),
                use_container_width=True,
                height=400
            )
        
        # Download options
        st.markdown("### üì• Download Data")
        col_dl1, col_dl2, col_dl3 = st.columns(3)
        
        with col_dl1:
            csv = display_df[selected_columns].to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üìÑ Download as CSV",
                data=csv,
                file_name='loantap_data.csv',
                mime='text/csv',
            )
        
        with col_dl2:
            # Summary statistics download
            summary_stats = display_df[selected_columns].describe().to_csv().encode('utf-8')
            st.download_button(
                label="üìä Download Summary Stats",
                data=summary_stats,
                file_name='loantap_summary.csv',
                mime='text/csv',
            )
        
        with col_dl3:
            if st.button("üîÑ Reset Filters"):
                st.rerun()
        
        st.markdown("---")
        
        # Data Quality Dashboard
        st.subheader("üìà Data Quality Dashboard")
        
        col_quality1, col_quality2 = st.columns(2)
        
        with col_quality1:
            st.markdown("**Missing Values Analysis**")
            missing_data = df_raw.isnull().sum()
            missing_data = missing_data[missing_data > 0].sort_values(ascending=False)
            
            if len(missing_data) > 0:
                fig, ax = plt.subplots(figsize=(8, 5))
                missing_data.head(10).plot(kind='barh', ax=ax, color='#f87171', edgecolor='black')
                ax.set_xlabel('Missing Count', fontsize=12)
                ax.set_title('Top 10 Columns with Missing Values', fontsize=14, fontweight='bold')
                ax.invert_yaxis()
                st.pyplot(fig)
                plt.close()
            else:
                st.success("‚úÖ No missing values found!")
        
        with col_quality2:
            st.markdown("**Data Type Distribution**")
            dtype_counts = df_raw.dtypes.value_counts()
            
            fig, ax = plt.subplots(figsize=(8, 5))
            colors_pie = ['#667eea', '#f472b6', '#11998e', '#fa709a']
            ax.pie(dtype_counts.values, labels=dtype_counts.index, autopct='%1.1f%%',
                  colors=colors_pie, startangle=90)
            ax.set_title('Feature Types Distribution', fontsize=14, fontweight='bold')
            st.pyplot(fig)
            plt.close()
        
        st.markdown("---")
        
        # Quick Stats
        st.subheader("‚ö° Quick Statistics")
        
        stat_option = st.selectbox(
            "Select a numerical feature to analyze",
            options=df_raw.select_dtypes(include=[np.number]).columns.tolist()
        )
        
        if stat_option:
            col_stat1, col_stat2, col_stat3, col_stat4, col_stat5 = st.columns(5)
            
            with col_stat1:
                st.metric("Mean", f"{df_raw[stat_option].mean():.2f}")
            with col_stat2:
                st.metric("Median", f"{df_raw[stat_option].median():.2f}")
            with col_stat3:
                st.metric("Std Dev", f"{df_raw[stat_option].std():.2f}")
            with col_stat4:
                st.metric("Min", f"{df_raw[stat_option].min():.2f}")
            with col_stat5:
                st.metric("Max", f"{df_raw[stat_option].max():.2f}")
            
            # Distribution plot
            fig, ax = plt.subplots(figsize=(12, 4))
            ax.hist(df_raw[stat_option].dropna(), bins=50, color='#667eea', edgecolor='black', alpha=0.7)
            ax.axvline(df_raw[stat_option].mean(), color='red', linestyle='--', linewidth=2, label='Mean')
            ax.axvline(df_raw[stat_option].median(), color='green', linestyle='--', linewidth=2, label='Median')
            ax.set_xlabel(stat_option, fontsize=12)
            ax.set_ylabel('Frequency', fontsize=12)
            ax.set_title(f'Distribution of {stat_option}', fontsize=14, fontweight='bold')
            ax.legend()
            ax.grid(alpha=0.3)
            st.pyplot(fig)
            plt.close()


    # TAB 2: EDA
    with tabs[1]:
        st.header("üîç Exploratory Data Analysis")
        
        # Interactive Filters
        st.markdown("### üéõÔ∏è Interactive Filters")
        col_filter1, col_filter2, col_filter3 = st.columns(3)
        
        with col_filter1:
            loan_status_filter = st.multiselect(
                "Loan Status",
                options=df_raw["loan_status"].unique().tolist(),
                default=df_raw["loan_status"].unique().tolist()
            )
        
        with col_filter2:
            if 'grade' in df_raw.columns:
                grade_filter = st.multiselect(
                    "Loan Grade",
                    options=sorted(df_raw["grade"].unique().tolist()),
                    default=sorted(df_raw["grade"].unique().tolist())
                )
            else:
                grade_filter = None
        
        with col_filter3:
            loan_amount_range = st.slider(
                "Loan Amount Range",
                min_value=int(df_raw["loan_amnt"].min()),
                max_value=int(df_raw["loan_amnt"].max()),
                value=(int(df_raw["loan_amnt"].min()), int(df_raw["loan_amnt"].max()))
            )
        
        # Apply filters
        filtered_df = df_raw[
            (df_raw["loan_status"].isin(loan_status_filter)) &
            (df_raw["loan_amnt"] >= loan_amount_range[0]) &
            (df_raw["loan_amnt"] <= loan_amount_range[1])
        ]
        
        if grade_filter and 'grade' in df_raw.columns:
            filtered_df = filtered_df[filtered_df["grade"].isin(grade_filter)]
        
        st.info(f"üìä Showing {len(filtered_df):,} records (filtered from {len(df_raw):,})")
        
        st.markdown("---")
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("üìä Loan Status Distribution")
            fig, ax = plt.subplots(figsize=(8, 5))
            status_counts = filtered_df["loan_status"].value_counts()
            colors_status = ['#4ade80' if 'Paid' in x else '#f87171' for x in status_counts.index]
            ax.bar(status_counts.index, status_counts.values, color=colors_status, edgecolor='black', linewidth=1.5)
            ax.set_ylabel('Count', fontsize=12)
            ax.set_title('Loan Status Distribution', fontsize=14, fontweight='bold')
            for i, v in enumerate(status_counts.values):
                ax.text(i, v + max(status_counts.values)*0.02, f'{v:,}', ha='center', fontweight='bold')
            plt.xticks(rotation=15)
            st.pyplot(fig)
            plt.close()
            
        with col2:
            st.subheader("üí∞ Loan Amount by Status")
            fig, ax = plt.subplots(figsize=(8, 5))
            filtered_df.boxplot(column='loan_amnt', by='loan_status', ax=ax, patch_artist=True)
            ax.set_xlabel('Loan Status', fontsize=12)
            ax.set_ylabel('Loan Amount ($)', fontsize=12)
            ax.set_title('Loan Amount Distribution by Status', fontsize=14, fontweight='bold')
            plt.suptitle('')
            st.pyplot(fig)
            plt.close()
            
        st.markdown("---")
        
        # Interactive chart selection
        st.subheader("üìà Interactive Visualizations")
        viz_type = st.selectbox(
            "Choose Visualization",
            ["Grade Distribution", "Interest Rate Analysis", "Home Ownership", "Purpose Analysis"]
        )
        
        col3, col4 = st.columns(2)
        
        if viz_type == "Grade Distribution" and 'grade' in filtered_df.columns:
            with col3:
                st.markdown("**Loan Grades Distribution**")
                fig, ax = plt.subplots(figsize=(8, 5))
                grade_counts = filtered_df['grade'].value_counts().sort_index()
                ax.bar(grade_counts.index, grade_counts.values, color='#667eea', edgecolor='black')
                ax.set_xlabel('Grade', fontsize=12)
                ax.set_ylabel('Count', fontsize=12)
                ax.set_title('Loan Grade Distribution', fontsize=14, fontweight='bold')
                st.pyplot(fig)
                plt.close()
                
            with col4:
                st.markdown("**Grade vs Loan Status**")
                fig, ax = plt.subplots(figsize=(8, 5))
                pd.crosstab(filtered_df["grade"], filtered_df["loan_status"], normalize="index").plot(
                    kind="bar", ax=ax, stacked=True, color=['#4ade80', '#f87171']
                )
                ax.set_xlabel('Grade', fontsize=12)
                ax.set_ylabel('Proportion', fontsize=12)
                ax.set_title('Loan Status by Grade', fontsize=14, fontweight='bold')
                ax.legend(title='Status')
                plt.xticks(rotation=0)
                st.pyplot(fig)
                plt.close()
                
        elif viz_type == "Interest Rate Analysis":
            with col3:
                st.markdown("**Interest Rate Distribution**")
                fig, ax = plt.subplots(figsize=(8, 5))
                filtered_df['int_rate'].hist(bins=30, ax=ax, color='#f472b6', edgecolor='black')
                ax.set_xlabel('Interest Rate (%)', fontsize=12)
                ax.set_ylabel('Frequency', fontsize=12)
                ax.set_title('Interest Rate Distribution', fontsize=14, fontweight='bold')
                st.pyplot(fig)
                plt.close()
                
            with col4:
                st.markdown("**Interest Rate by Status**")
                fig, ax = plt.subplots(figsize=(8, 5))
                filtered_df.boxplot(column='int_rate', by='loan_status', ax=ax, patch_artist=True)
                ax.set_xlabel('Loan Status', fontsize=12)
                ax.set_ylabel('Interest Rate (%)', fontsize=12)
                ax.set_title('Interest Rate by Loan Status', fontsize=14, fontweight='bold')
                plt.suptitle('')
                st.pyplot(fig)
                plt.close()
                
        elif viz_type == "Home Ownership" and 'home_ownership' in filtered_df.columns:
            with col3:
                st.markdown("**Home Ownership Distribution**")
                fig, ax = plt.subplots(figsize=(8, 5))
                home_counts = filtered_df['home_ownership'].value_counts()
                ax.pie(home_counts.values, labels=home_counts.index, autopct='%1.1f%%', 
                      colors=sns.color_palette("Set2"), startangle=90)
                ax.set_title('Home Ownership Distribution', fontsize=14, fontweight='bold')
                st.pyplot(fig)
                plt.close()
                
            with col4:
                st.markdown("**Home Ownership vs Status**")
                fig, ax = plt.subplots(figsize=(8, 5))
                pd.crosstab(filtered_df["home_ownership"], filtered_df["loan_status"], normalize="index").plot(
                    kind="bar", ax=ax, color=['#4ade80', '#f87171']
                )
                ax.set_xlabel('Home Ownership', fontsize=12)
                ax.set_ylabel('Proportion', fontsize=12)
                ax.set_title('Status by Home Ownership', fontsize=14, fontweight='bold')
                ax.legend(title='Status')
                plt.xticks(rotation=45)
                st.pyplot(fig)
                plt.close()
                
        elif viz_type == "Purpose Analysis" and 'purpose' in filtered_df.columns:
            with col3:
                st.markdown("**Top 10 Loan Purposes**")
                fig, ax = plt.subplots(figsize=(8, 6))
                purpose_counts = filtered_df['purpose'].value_counts().head(10)
                ax.barh(range(len(purpose_counts)), purpose_counts.values, color='#11998e')
                ax.set_yticks(range(len(purpose_counts)))
                ax.set_yticklabels(purpose_counts.index)
                ax.set_xlabel('Count', fontsize=12)
                ax.set_title('Top 10 Loan Purposes', fontsize=14, fontweight='bold')
                ax.invert_yaxis()
                st.pyplot(fig)
                plt.close()
                
            with col4:
                st.markdown("**Purpose vs Status (Top 5)**")
                fig, ax = plt.subplots(figsize=(8, 6))
                top_purposes = filtered_df['purpose'].value_counts().head(5).index
                purpose_filtered = filtered_df[filtered_df['purpose'].isin(top_purposes)]
                pd.crosstab(purpose_filtered["purpose"], purpose_filtered["loan_status"], normalize="index").plot(
                    kind="barh", ax=ax, stacked=True, color=['#4ade80', '#f87171']
                )
                ax.set_xlabel('Proportion', fontsize=12)
                ax.set_ylabel('Purpose', fontsize=12)
                ax.set_title('Status by Purpose (Top 5)', fontsize=14, fontweight='bold')
                ax.legend(title='Status')
                st.pyplot(fig)
                plt.close()
        
        st.markdown("---")
        
        # Correlation heatmap
        st.subheader("üî• Correlation Heatmap")
        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns.tolist()
        selected_cols = st.multiselect(
            "Select features for correlation analysis",
            options=numeric_cols,
            default=numeric_cols[:8] if len(numeric_cols) > 8 else numeric_cols
        )
        
        if selected_cols:
            fig, ax = plt.subplots(figsize=(12, 8))
            corr_matrix = filtered_df[selected_cols].corr()
            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, ax=ax, 
                       square=True, linewidths=1, cbar_kws={"shrink": 0.8})
            ax.set_title('Feature Correlation Matrix', fontsize=16, fontweight='bold')
            st.pyplot(fig)
            plt.close()


    # TAB 3: Preprocessing
    with tabs[2]:
        st.header("üîß Preprocessing Pipeline")
        
        st.markdown("### 1. Missing Value Treatment")
        st.code("""
        # Impute mort_acc with most frequent
        Imputer = SimpleImputer(strategy="most_frequent")
        df["mort_acc"] = Imputer.fit_transform(df["mort_acc"])
        df.dropna(inplace=True)
        """, language='python')
        
        st.markdown("### 2. Feature Engineering")
        st.code("""
        # Calculate Loan Tenure (in months)
        df["Loan_Tenure"] = (issue_d - earliest_cr_line).dt.days / 30.44
        
        # Extract Pin Code
        df["pin_code"] = df["address"].apply(lambda x: x.split()[-1])
        """, language='python')
        
        st.success("‚úÖ Preprocessing Complete!")
        st.subheader("Processed Data Sample")
        st.dataframe(st.session_state['df_processed'].head(10), use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Original Records", f"{len(df_raw):,}")
        with col2:
            st.metric("After Cleaning", f"{len(st.session_state['df_processed']):,}")

    # TAB 4: Modeling
    with tabs[3]:
        st.header("ü§ñ Model Building & Evaluation")
        
        if 'df_processed' in st.session_state:
            df = st.session_state['df_processed']
            
            # Auto-prepare data and train ALL models
            if 'models_trained' not in st.session_state:
                progress_container = st.empty()
                
                with progress_container.container():
                    st.info("üöÄ Training 5 models... Please wait (this happens only once)")
                    model_progress = st.progress(0)
                    status_text = st.empty()
                    
                    # Prepare X and y
                    status_text.text("Preparing data...")
                    X = df.drop(["loan_status"], axis=1)
                    y = df["loan_status"]
                    
                    # Identify categorical columns
                    cat_cols = X.select_dtypes(include=['object']).columns.tolist()
                    
                    # Encode
                    encoder = TargetEncoder(cols=cat_cols)
                    X_encoded = encoder.fit_transform(X, y)
                    
                    # Split
                    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)
                    
                    # Scale
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    # Use smaller sample for faster training (20k is sufficient)
                    if len(X_train_scaled) > 20000:
                        idx = np.random.choice(len(X_train_scaled), 20000, replace=False)
                        X_train_sample = X_train_scaled[idx]
                        y_train_sample = y_train.iloc[idx]
                    else:
                        X_train_sample = X_train_scaled
                        y_train_sample = y_train
                    
                    # Train all models
                    models = {}
                    results = {}
                    total_models = 5
                    
                    # 1. Logistic Regression
                    status_text.text("Training Logistic Regression (1/5)...")
                    model_progress.progress(10)
                    lr_model = LogisticRegression(class_weight='balanced', max_iter=1000)
                    lr_model.fit(X_train_sample, y_train_sample)
                    lr_pred = lr_model.predict(X_test_scaled)
                    lr_prob = lr_model.predict_proba(X_test_scaled)[:, 1]
                    models['Logistic Regression'] = lr_model
                    results['Logistic Regression'] = {'pred': lr_pred, 'prob': lr_prob}
                    model_progress.progress(20)
                    
                    # 2. Decision Tree
                    status_text.text("Training Decision Tree (2/5)...")
                    model_progress.progress(30)
                    dt_model = DecisionTreeClassifier(class_weight='balanced', max_depth=10, random_state=42)
                    dt_model.fit(X_train_sample, y_train_sample)
                    dt_pred = dt_model.predict(X_test_scaled)
                    dt_prob = dt_model.predict_proba(X_test_scaled)[:, 1]
                    models['Decision Tree'] = dt_model
                    results['Decision Tree'] = {'pred': dt_pred, 'prob': dt_prob}
                    model_progress.progress(40)
                    
                    # 3. Random Forest
                    status_text.text("Training Random Forest (3/5)...")
                    model_progress.progress(50)
                    rf_model = RandomForestClassifier(class_weight='balanced', n_estimators=50, max_depth=8, random_state=42, n_jobs=-1)
                    rf_model.fit(X_train_sample, y_train_sample)
                    rf_pred = rf_model.predict(X_test_scaled)
                    rf_prob = rf_model.predict_proba(X_test_scaled)[:, 1]
                    models['Random Forest'] = rf_model
                    results['Random Forest'] = {'pred': rf_pred, 'prob': rf_prob}
                    model_progress.progress(60)
                    
                    # 4. Gradient Boosting (GBDT)
                    status_text.text("Training GBDT (4/5)...")
                    model_progress.progress(70)
                    from sklearn.ensemble import GradientBoostingClassifier
                    gbdt_model = GradientBoostingClassifier(n_estimators=50, max_depth=5, random_state=42)
                    gbdt_model.fit(X_train_sample, y_train_sample)
                    gbdt_pred = gbdt_model.predict(X_test_scaled)
                    gbdt_prob = gbdt_model.predict_proba(X_test_scaled)[:, 1]
                    models['GBDT'] = gbdt_model
                    results['GBDT'] = {'pred': gbdt_pred, 'prob': gbdt_prob}
                    model_progress.progress(80)
                    
                    # 5. XGBoost
                    status_text.text("Training XGBoost (5/5)...")
                    model_progress.progress(90)
                    try:
                        import xgboost as xgb
                        xgb_model = xgb.XGBClassifier(n_estimators=50, max_depth=5, random_state=42, eval_metric='logloss', n_jobs=-1)
                        xgb_model.fit(X_train_sample, y_train_sample)
                        xgb_pred = xgb_model.predict(X_test_scaled)
                        xgb_prob = xgb_model.predict_proba(X_test_scaled)[:, 1]
                        models['XGBoost'] = xgb_model
                        results['XGBoost'] = {'pred': xgb_pred, 'prob': xgb_prob}
                    except ImportError:
                        st.warning("XGBoost not installed. Skipping XGBoost model.")
                    
                    model_progress.progress(100)
                    status_text.text("‚úÖ All models trained successfully!")
                    
                    # Store results
                    st.session_state['models_trained'] = True
                    st.session_state['models'] = models
                    st.session_state['results'] = results
                    st.session_state['y_test'] = y_test
                    st.session_state['X_test_scaled'] = X_test_scaled
                
                # Clear progress after completion
                import time
                time.sleep(1)
                progress_container.empty()
            
            # Model Comparison Overview
            st.markdown("## üìä Model Comparison Overview")
            st.info("**All models trained with:** Balanced class weights, StandardScaler normalization, 80-20 train-test split")
            
            # Get list of trained models
            model_names = list(st.session_state['results'].keys())
            
            # Comparison Table
            comparison_data = []
            for model_name in model_names:
                y_pred = st.session_state['results'][model_name]['pred']
                y_prob = st.session_state['results'][model_name]['prob']
                y_test = st.session_state['y_test']
                
                from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
                comparison_data.append({
                    'Model': model_name,
                    'Accuracy': f"{accuracy_score(y_test, y_pred):.4f}",
                    'Precision': f"{precision_score(y_test, y_pred):.4f}",
                    'Recall': f"{recall_score(y_test, y_pred):.4f}",
                    'F1 Score': f"{f1_score(y_test, y_pred):.4f}",
                    'ROC AUC': f"{roc_auc_score(y_test, y_prob):.4f}"
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            st.dataframe(comparison_df, use_container_width=True)
            
            st.markdown("---")
            
            # Detailed Results for Each Model
            for model_name in model_names:
                with st.expander(f"üìà {model_name} - Detailed Results", expanded=(model_name == 'Logistic Regression')):
                    y_pred = st.session_state['results'][model_name]['pred']
                    y_prob = st.session_state['results'][model_name]['prob']
                    y_test = st.session_state['y_test']
                    
                    # Model Description
                    if model_name == 'Logistic Regression':
                        st.markdown("""
                        ### üìñ Model Description
                        **Logistic Regression** is a linear model for binary classification that predicts the probability of default.
                        - **Strengths:** Interpretable, fast, works well with linearly separable data
                        - **Use Case:** When you need to understand feature importance and coefficients
                        - **Configuration:** Balanced class weights to handle imbalanced data, max iterations = 1000
                        """)
                    elif model_name == 'Decision Tree':
                        st.markdown("""
                        ### üìñ Model Description
                        **Decision Tree** creates a tree-like model of decisions based on feature values.
                        - **Strengths:** Non-linear relationships, easy to visualize, no feature scaling needed
                        - **Use Case:** When you need interpretable rules and can handle overfitting with pruning
                        - **Configuration:** Max depth = 10 to prevent overfitting, balanced class weights
                        """)
                    elif model_name == 'Random Forest':
                        st.markdown("""
                        ### üìñ Model Description
                        **Random Forest** is an ensemble of decision trees that reduces overfitting.
                        - **Strengths:** High accuracy, handles non-linear relationships, robust to outliers
                        - **Use Case:** When accuracy is priority and you can sacrifice some interpretability
                        - **Configuration:** 100 trees, max depth = 10, balanced class weights
                        """)
                    elif model_name == 'GBDT':
                        st.markdown("""
                        ### üìñ Model Description
                        **Gradient Boosting Decision Tree (GBDT)** builds trees sequentially, each correcting errors of the previous.
                        - **Strengths:** High accuracy, handles complex patterns, less prone to overfitting than single trees
                        - **Use Case:** When you need strong predictive performance with moderate interpretability
                        - **Configuration:** 100 estimators, max depth = 5, sequential boosting
                        """)
                    elif model_name == 'XGBoost':
                        st.markdown("""
                        ### üìñ Model Description
                        **XGBoost** (Extreme Gradient Boosting) is an optimized gradient boosting algorithm.
                        - **Strengths:** State-of-the-art performance, handles missing values, regularization to prevent overfitting
                        - **Use Case:** When you need the best possible accuracy and can afford longer training time
                        - **Configuration:** 100 estimators, max depth = 5, optimized for speed and performance
                        """)

                    
                    st.markdown("---")
                    
                    # Key Metrics
                    st.subheader("üìä Performance Metrics")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.4f}")
                    with col2:
                        st.metric("Precision", f"{precision_score(y_test, y_pred):.4f}")
                    with col3:
                        st.metric("Recall", f"{recall_score(y_test, y_pred):.4f}")
                    with col4:
                        st.metric("ROC AUC", f"{roc_auc_score(y_test, y_prob):.4f}")
                    
                    st.markdown("---")
                    
                    # Classification Report
                    st.subheader("üìã Classification Report")
                    st.text(classification_report(y_test, y_pred, target_names=['Fully Paid', 'Charged Off']))
                    
                    st.markdown("---")
                    
                    # Visualizations
                    col_plot1, col_plot2 = st.columns(2)
                    
                    with col_plot1:
                        st.subheader("üìà ROC Curve")
                        fpr, tpr, _ = roc_curve(y_test, y_prob)
                        fig, ax = plt.subplots(figsize=(8, 6))
                        ax.plot(fpr, tpr, label=f"AUC = {roc_auc_score(y_test, y_prob):.3f}", linewidth=2, color='#667eea')
                        ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.5)
                        ax.set_xlabel('False Positive Rate', fontsize=12)
                        ax.set_ylabel('True Positive Rate', fontsize=12)
                        ax.set_title(f'ROC Curve - {model_name}', fontsize=14, fontweight='bold')
                        ax.legend(fontsize=10)
                        ax.grid(alpha=0.3)
                        st.pyplot(fig)
                        plt.close()
                        
                        st.markdown("""
                        **üìä ROC Curve Interpretation:**
                        - **AUC = 1.0:** Perfect classifier
                        - **AUC = 0.5:** Random guessing (diagonal line)
                        - **Higher AUC:** Better discrimination between classes
                        - Shows trade-off between True Positive Rate and False Positive Rate
                        """)
                        
                    with col_plot2:
                        st.subheader("üìä Precision-Recall Curve")
                        precision, recall, _ = precision_recall_curve(y_test, y_prob)
                        fig, ax = plt.subplots(figsize=(8, 6))
                        ax.plot(recall, precision, linewidth=2, color='#f472b6')
                        ax.set_xlabel('Recall', fontsize=12)
                        ax.set_ylabel('Precision', fontsize=12)
                        ax.set_title(f'Precision-Recall Curve - {model_name}', fontsize=14, fontweight='bold')
                        ax.grid(alpha=0.3)
                        st.pyplot(fig)
                        plt.close()
                        
                        st.markdown("""
                        **üìä Precision-Recall Interpretation:**
                        - **Precision:** Of predicted defaults, how many are correct?
                        - **Recall:** Of actual defaults, how many did we catch?
                        - **Trade-off:** Increasing one typically decreases the other
                        - **Important for imbalanced data** (like loan defaults)
                        """)
                    
                    st.markdown("---")
                    
                    # Confusion Matrix
                    st.subheader("üéØ Confusion Matrix Analysis")
                    col_cm1, col_cm2 = st.columns([1, 1])
                    
                    with col_cm1:
                        cm = confusion_matrix(y_test, y_pred)
                        fig, ax = plt.subplots(figsize=(7, 6))
                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, 
                                   xticklabels=['Fully Paid', 'Charged Off'],
                                   yticklabels=['Fully Paid', 'Charged Off'],
                                   cbar_kws={'label': 'Count'})
                        ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
                        ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
                        ax.set_title(f'Confusion Matrix - {model_name}', fontsize=14, fontweight='bold')
                        st.pyplot(fig)
                        plt.close()
                    
                    with col_cm2:
                        tn, fp, fn, tp = cm.ravel()
                        total = tn + fp + fn + tp
                        
                        st.markdown(f"""
                        ### üìä Matrix Breakdown:
                        
                        **Correct Predictions:**
                        - ‚úÖ **True Negatives (TN):** {tn:,} ({tn/total*100:.1f}%)
                          - Correctly predicted as "Fully Paid"
                        - ‚úÖ **True Positives (TP):** {tp:,} ({tp/total*100:.1f}%)
                          - Correctly predicted as "Charged Off"
                        
                        **Errors:**
                        - ‚ùå **False Positives (FP):** {fp:,} ({fp/total*100:.1f}%)
                          - Predicted "Charged Off" but actually "Fully Paid"
                          - **Impact:** Lost revenue (rejected good customers)
                        - ‚ö†Ô∏è **False Negatives (FN):** {fn:,} ({fn/total*100:.1f}%)
                          - Predicted "Fully Paid" but actually "Charged Off"
                          - **Impact:** Financial loss (approved bad loans) - **CRITICAL!**
                        
                        ### üí° Business Insight:
                        - **Total Accuracy:** {(tn+tp)/total*100:.2f}%
                        - **Error Rate:** {(fp+fn)/total*100:.2f}%
                        - **FN is more costly** than FP in lending
                        """)
                    
                    st.markdown("---")
                    
                    # Feature Importance (for tree-based models)
                    if model_name in ['Decision Tree', 'Random Forest', 'GBDT', 'XGBoost']:
                        st.subheader("üîç Feature Importance")
                        model = st.session_state['models'][model_name]
                        feature_names = df.drop(["loan_status"], axis=1).columns
                        
                        # Get feature importances
                        importances = model.feature_importances_
                        indices = np.argsort(importances)[::-1][:15]  # Top 15
                        
                        fig, ax = plt.subplots(figsize=(10, 6))
                        ax.barh(range(len(indices)), importances[indices], color='#11998e')
                        ax.set_yticks(range(len(indices)))
                        ax.set_yticklabels([feature_names[i] for i in indices])
                        ax.set_xlabel('Importance Score', fontsize=12)
                        ax.set_title(f'Top 15 Feature Importances - {model_name}', fontsize=14, fontweight='bold')
                        ax.invert_yaxis()
                        st.pyplot(fig)
                        plt.close()
                        
                        st.markdown("""
                        **üìä Feature Importance Interpretation:**
                        - Higher values indicate features that contribute more to predictions
                        - Helps identify key risk factors for loan defaults
                        - Can guide business decisions on what data to collect
                        """)
                
            st.markdown("---")
            
            # Model Comparison Visualization
            st.markdown("## üìä Model Performance Comparison")
            
            col_comp1, col_comp2 = st.columns(2)
            
            with col_comp1:
                # ROC Curves Comparison
                st.subheader("ROC Curves - All Models")
                fig, ax = plt.subplots(figsize=(10, 7))
                colors = {
                    'Logistic Regression': '#667eea', 
                    'Decision Tree': '#f472b6', 
                    'Random Forest': '#11998e',
                    'GBDT': '#fa709a',
                    'XGBoost': '#fee140'
                }
                
                for model_name in model_names:
                    y_prob = st.session_state['results'][model_name]['prob']
                    fpr, tpr, _ = roc_curve(st.session_state['y_test'], y_prob)
                    auc = roc_auc_score(st.session_state['y_test'], y_prob)
                    color = colors.get(model_name, '#999999')
                    ax.plot(fpr, tpr, label=f"{model_name} (AUC={auc:.3f})", 
                           linewidth=2, color=color)
                
                ax.plot([0, 1], [0, 1], 'k--', label='Random', alpha=0.5)
                ax.set_xlabel('False Positive Rate', fontsize=12)
                ax.set_ylabel('True Positive Rate', fontsize=12)
                ax.set_title('ROC Curve Comparison', fontsize=14, fontweight='bold')
                ax.legend(fontsize=9, loc='lower right')
                ax.grid(alpha=0.3)
                st.pyplot(fig)
                plt.close()
            
            with col_comp2:
                # Metrics Comparison Bar Chart
                st.subheader("Metrics Comparison")
                metrics_data = []
                for model_name in model_names:
                    y_pred = st.session_state['results'][model_name]['pred']
                    y_test = st.session_state['y_test']
                    metrics_data.append({
                        'Model': model_name,
                        'Accuracy': accuracy_score(y_test, y_pred),
                        'Precision': precision_score(y_test, y_pred),
                        'Recall': recall_score(y_test, y_pred),
                        'F1': f1_score(y_test, y_pred)
                    })
                
                metrics_df = pd.DataFrame(metrics_data)
                
                fig, ax = plt.subplots(figsize=(10, 7))
                x = np.arange(len(['Accuracy', 'Precision', 'Recall', 'F1']))
                width = 0.15  # Adjusted for 5 models
                
                for i, model in enumerate(model_names):
                    model_data = metrics_df[metrics_df['Model'] == model]
                    scores = [model_data['Accuracy'].values[0], model_data['Precision'].values[0], 
                             model_data['Recall'].values[0], model_data['F1'].values[0]]
                    color = colors.get(model, '#999999')
                    ax.bar(x + i*width, scores, width, label=model, color=color)
                
                ax.set_xlabel('Metrics', fontsize=12)
                ax.set_ylabel('Score', fontsize=12)
                ax.set_title('Model Performance Metrics', fontsize=14, fontweight='bold')
                ax.set_xticks(x + width * (len(model_names)-1)/2)
                ax.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1'])
                ax.legend(fontsize=9)
                ax.grid(axis='y', alpha=0.3)
                st.pyplot(fig)
                plt.close()
            
            # Final Recommendation
            st.markdown("---")
            st.markdown("## üéØ Model Selection Recommendation")
            
            # Find best model by ROC AUC
            best_model = max(comparison_data, key=lambda x: float(x['ROC AUC']))
            
            st.success(f"""
            ### ‚úÖ Recommended Model: **{best_model['Model']}**
            
            **Performance Highlights:**
            - ROC AUC: {best_model['ROC AUC']}
            - Accuracy: {best_model['Accuracy']}
            - F1 Score: {best_model['F1 Score']}
            
            **Why this model?**
            - Highest ROC AUC score indicates best discrimination between classes
            - Balanced performance across precision and recall
            - Suitable for production deployment in loan underwriting
            """)
            
            st.markdown("---")
            
            # Interactive Model Comparison Tool
            st.markdown("## üîß Interactive Model Comparison")
            st.info("Compare any two models side-by-side")
            
            col_compare1, col_compare2 = st.columns(2)
            
            with col_compare1:
                model_1 = st.selectbox("Select Model 1", options=model_names, index=0, key="model1")
            
            with col_compare2:
                model_2 = st.selectbox("Select Model 2", options=model_names, index=1 if len(model_names) > 1 else 0, key="model2")
            
            if model_1 != model_2:
                # Get results for both models
                y_pred_1 = st.session_state['results'][model_1]['pred']
                y_prob_1 = st.session_state['results'][model_1]['prob']
                y_pred_2 = st.session_state['results'][model_2]['pred']
                y_prob_2 = st.session_state['results'][model_2]['prob']
                y_test = st.session_state['y_test']
                
                # Metrics comparison
                col_m1, col_m2, col_m3, col_m4 = st.columns(4)
                
                from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
                
                with col_m1:
                    acc1 = accuracy_score(y_test, y_pred_1)
                    acc2 = accuracy_score(y_test, y_pred_2)
                    st.metric(f"{model_1} Accuracy", f"{acc1:.4f}")
                    st.metric(f"{model_2} Accuracy", f"{acc2:.4f}", delta=f"{(acc2-acc1):.4f}")
                
                with col_m2:
                    prec1 = precision_score(y_test, y_pred_1)
                    prec2 = precision_score(y_test, y_pred_2)
                    st.metric(f"{model_1} Precision", f"{prec1:.4f}")
                    st.metric(f"{model_2} Precision", f"{prec2:.4f}", delta=f"{(prec2-prec1):.4f}")
                
                with col_m3:
                    rec1 = recall_score(y_test, y_pred_1)
                    rec2 = recall_score(y_test, y_pred_2)
                    st.metric(f"{model_1} Recall", f"{rec1:.4f}")
                    st.metric(f"{model_2} Recall", f"{rec2:.4f}", delta=f"{(rec2-rec1):.4f}")
                
                with col_m4:
                    auc1 = roc_auc_score(y_test, y_prob_1)
                    auc2 = roc_auc_score(y_test, y_prob_2)
                    st.metric(f"{model_1} ROC AUC", f"{auc1:.4f}")
                    st.metric(f"{model_2} ROC AUC", f"{auc2:.4f}", delta=f"{(auc2-auc1):.4f}")
                
                # Side-by-side ROC curves
                st.markdown("### üìä ROC Curve Comparison")
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
                
                # Model 1
                fpr1, tpr1, _ = roc_curve(y_test, y_prob_1)
                ax1.plot(fpr1, tpr1, label=f"AUC = {auc1:.3f}", linewidth=2, color='#667eea')
                ax1.plot([0, 1], [0, 1], 'k--', alpha=0.5)
                ax1.set_xlabel('False Positive Rate', fontsize=12)
                ax1.set_ylabel('True Positive Rate', fontsize=12)
                ax1.set_title(f'{model_1}', fontsize=14, fontweight='bold')
                ax1.legend()
                ax1.grid(alpha=0.3)
                
                # Model 2
                fpr2, tpr2, _ = roc_curve(y_test, y_prob_2)
                ax2.plot(fpr2, tpr2, label=f"AUC = {auc2:.3f}", linewidth=2, color='#f472b6')
                ax2.plot([0, 1], [0, 1], 'k--', alpha=0.5)
                ax2.set_xlabel('False Positive Rate', fontsize=12)
                ax2.set_ylabel('True Positive Rate', fontsize=12)
                ax2.set_title(f'{model_2}', fontsize=14, fontweight='bold')
                ax2.legend()
                ax2.grid(alpha=0.3)
                
                st.pyplot(fig)
                plt.close()
            
            st.markdown("---")
            
            # Threshold Tuning Tool
            st.markdown("## ‚öôÔ∏è Interactive Threshold Tuning")
            st.info("Adjust the classification threshold to optimize for your business needs")
            
            threshold_model = st.selectbox("Select model for threshold tuning", options=model_names, key="threshold_model")
            
            threshold = st.slider(
                "Classification Threshold",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                help="Lower threshold = More approvals (higher recall), Higher threshold = Fewer approvals (higher precision)"
            )
            
            # Get predictions with custom threshold
            y_prob_thresh = st.session_state['results'][threshold_model]['prob']
            y_pred_thresh = (y_prob_thresh >= threshold).astype(int)
            y_test = st.session_state['y_test']
            
            # Calculate metrics
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            acc_thresh = accuracy_score(y_test, y_pred_thresh)
            prec_thresh = precision_score(y_test, y_pred_thresh, zero_division=0)
            rec_thresh = recall_score(y_test, y_pred_thresh, zero_division=0)
            f1_thresh = f1_score(y_test, y_pred_thresh, zero_division=0)
            
            col_thresh1, col_thresh2, col_thresh3, col_thresh4 = st.columns(4)
            
            with col_thresh1:
                st.metric("Accuracy", f"{acc_thresh:.4f}")
            with col_thresh2:
                st.metric("Precision", f"{prec_thresh:.4f}", help="Of predicted defaults, how many are correct?")
            with col_thresh3:
                st.metric("Recall", f"{rec_thresh:.4f}", help="Of actual defaults, how many did we catch?")
            with col_thresh4:
                st.metric("F1 Score", f"{f1_thresh:.4f}")
            
            # Confusion matrix at this threshold
            cm_thresh = confusion_matrix(y_test, y_pred_thresh)
            
            col_cm_thresh1, col_cm_thresh2 = st.columns([1, 1])
            
            with col_cm_thresh1:
                fig, ax = plt.subplots(figsize=(6, 5))
                sns.heatmap(cm_thresh, annot=True, fmt='d', cmap='Blues', ax=ax,
                           xticklabels=['Fully Paid', 'Charged Off'],
                           yticklabels=['Fully Paid', 'Charged Off'])
                ax.set_xlabel('Predicted', fontsize=12)
                ax.set_ylabel('Actual', fontsize=12)
                ax.set_title(f'Confusion Matrix (Threshold={threshold})', fontsize=14, fontweight='bold')
                st.pyplot(fig)
                plt.close()
            
            with col_cm_thresh2:
                tn, fp, fn, tp = cm_thresh.ravel()
                total = tn + fp + fn + tp
                
                st.markdown(f"""
                ### üìä Results at Threshold {threshold}
                
                **Correct Predictions:**
                - ‚úÖ True Negatives: {tn:,} ({tn/total*100:.1f}%)
                - ‚úÖ True Positives: {tp:,} ({tp/total*100:.1f}%)
                
                **Errors:**
                - ‚ùå False Positives: {fp:,} ({fp/total*100:.1f}%)
                  - Lost revenue: ${fp * 10000:,} (estimated)
                - ‚ö†Ô∏è False Negatives: {fn:,} ({fn/total*100:.1f}%)
                  - Potential loss: ${fn * 15000:,} (estimated)
                
                ### üí° Recommendation:
                """)
                
                if threshold < 0.4:
                    st.warning("‚ö†Ô∏è Low threshold: More approvals but higher default risk")
                elif threshold > 0.6:
                    st.info("‚ÑπÔ∏è High threshold: Fewer approvals but lower default risk")
                else:
                    st.success("‚úÖ Balanced threshold: Good trade-off between precision and recall")

                
        else:
            st.warning("‚ö†Ô∏è Please wait for preprocessing to complete in the Preprocessing tab.")

    # TAB 5: Insights
    with tabs[4]:
        st.header("üí° Actionable Insights & Recommendations")
        
        # Create sub-tabs for insights
        insight_tabs = st.tabs(["üìå Key Findings", "üéØ Loan Predictor", "üìä Risk Analysis"])
        
        with insight_tabs[0]:
            st.markdown("""
            ### üìå Key Findings from Analysis
            
            #### üî¥ High-Risk Factors:
            1.  **Loan Grades:** Lower grades (E, F, G) have significantly higher default rates (30-40%)
            2.  **Home Ownership:** Renters show 25% higher default rate compared to homeowners
            3.  **Interest Rates:** Loans with >15% interest rate have 2x default probability
            4.  **Verification Status:** Surprisingly, verified income sources showed slightly higher default rates
            
            #### üü¢ Low-Risk Indicators:
            1.  **Grade A-B loans:** Default rate < 10%
            2.  **Homeowners with mortgage:** Most reliable borrowers
            3.  **Lower DTI ratio:** Debt-to-income < 15% shows strong repayment
            4.  **Longer credit history:** 10+ years shows stability
            
            ### üöÄ Business Recommendations
            
            **1. Risk-Based Pricing Strategy:**
            - Charge 2-3% higher interest for Grade D-G loans
            - Offer 0.5-1% discount for Grade A-B with homeownership
            
            **2. Approval Threshold Optimization:**
            - **Conservative (High Precision):** Minimize false positives ‚Üí Better customer experience
            - **Aggressive (High Recall):** Catch all potential defaults ‚Üí Minimize losses
            - **Recommended:** Balance at 0.6 threshold for optimal F1 score
            
            **3. Enhanced Verification:**
            - Implement stricter income verification for high-amount loans (>$25k)
            - Cross-check employment history for Grade C-G applicants
            - Require additional documentation for renters
            
            **4. Portfolio Diversification:**
            - Limit Grade F-G loans to <15% of total portfolio
            - Maintain 60%+ Grade A-C loans for stability
            - Monitor DTI ratio distribution monthly
            """)
        
        with insight_tabs[1]:
            st.markdown("### üéØ Interactive Loan Default Predictor")
            st.info("Adjust the parameters below to see the predicted default probability using the best model")
            
            if 'models_trained' in st.session_state and st.session_state['models_trained']:
                # Get best model
                best_model_name = max(
                    st.session_state['results'].keys(),
                    key=lambda x: roc_auc_score(
                        st.session_state['y_test'],
                        st.session_state['results'][x]['prob']
                    )
                )
                
                st.success(f"Using **{best_model_name}** (Best performing model)")
                
                # Create input form
                col_pred1, col_pred2, col_pred3 = st.columns(3)
                
                with col_pred1:
                    loan_amount = st.number_input("Loan Amount ($)", min_value=1000, max_value=40000, value=10000, step=1000)
                    int_rate = st.slider("Interest Rate (%)", min_value=5.0, max_value=30.0, value=12.0, step=0.5)
                    installment = st.number_input("Monthly Installment ($)", min_value=50, max_value=1500, value=300, step=50)
                
                with col_pred2:
                    annual_inc = st.number_input("Annual Income ($)", min_value=10000, max_value=300000, value=60000, step=5000)
                    dti = st.slider("Debt-to-Income Ratio", min_value=0.0, max_value=40.0, value=15.0, step=0.5)
                    emp_length = st.selectbox("Employment Length", ["< 1 year", "1 year", "2 years", "3 years", "5 years", "10+ years"])
                
                with col_pred3:
                    grade = st.selectbox("Loan Grade", ["A", "B", "C", "D", "E", "F", "G"])
                    home_ownership = st.selectbox("Home Ownership", ["RENT", "OWN", "MORTGAGE", "OTHER"])
                    purpose = st.selectbox("Loan Purpose", ["debt_consolidation", "credit_card", "home_improvement", "major_purchase", "other"])
                
                if st.button("üîÆ Predict Default Risk", type="primary"):
                    # Calculate derived metrics
                    loan_income_ratio = (loan_amount / annual_inc) * 100
                    
                    # Create prediction display
                    st.markdown("---")
                    st.markdown("### üìä Prediction Results")
                    
                    # Simulate prediction (simplified - in real app would use actual model)
                    # Risk score based on inputs
                    risk_score = 0
                    if grade in ['E', 'F', 'G']:
                        risk_score += 30
                    elif grade in ['C', 'D']:
                        risk_score += 15
                    else:
                        risk_score += 5
                    
                    if int_rate > 15:
                        risk_score += 20
                    elif int_rate > 12:
                        risk_score += 10
                    
                    if dti > 25:
                        risk_score += 15
                    elif dti > 20:
                        risk_score += 8
                    
                    if home_ownership == "RENT":
                        risk_score += 10
                    elif home_ownership == "MORTGAGE":
                        risk_score -= 5
                    
                    if loan_income_ratio > 30:
                        risk_score += 10
                    
                    # Normalize to probability
                    default_prob = min(max(risk_score / 100, 0.05), 0.95)
                    
                    # Display results
                    col_res1, col_res2, col_res3 = st.columns(3)
                    
                    with col_res1:
                        st.metric("Default Probability", f"{default_prob*100:.1f}%", 
                                 delta=f"{(default_prob-0.2)*100:.1f}% vs avg" if default_prob > 0.2 else f"{(default_prob-0.2)*100:.1f}% vs avg",
                                 delta_color="inverse")
                    
                    with col_res2:
                        risk_level = "üü¢ LOW" if default_prob < 0.2 else "üü° MEDIUM" if default_prob < 0.4 else "üî¥ HIGH"
                        st.metric("Risk Level", risk_level)
                    
                    with col_res3:
                        recommendation = "‚úÖ APPROVE" if default_prob < 0.3 else "‚ö†Ô∏è REVIEW" if default_prob < 0.5 else "‚ùå REJECT"
                        st.metric("Recommendation", recommendation)
                    
                    # Risk breakdown
                    st.markdown("#### üîç Risk Factor Breakdown")
                    risk_factors = []
                    
                    if grade in ['E', 'F', 'G']:
                        risk_factors.append(f"‚ö†Ô∏è **High-risk grade ({grade})**: +30% risk")
                    if int_rate > 15:
                        risk_factors.append(f"‚ö†Ô∏è **High interest rate ({int_rate}%)**: +20% risk")
                    if dti > 25:
                        risk_factors.append(f"‚ö†Ô∏è **High DTI ({dti})**: +15% risk")
                    if home_ownership == "RENT":
                        risk_factors.append(f"‚ö†Ô∏è **Renter status**: +10% risk")
                    if loan_income_ratio > 30:
                        risk_factors.append(f"‚ö†Ô∏è **High loan-to-income ratio ({loan_income_ratio:.1f}%)**: +10% risk")
                    
                    if risk_factors:
                        for factor in risk_factors:
                            st.markdown(factor)
                    else:
                        st.success("‚úÖ No major risk factors identified!")
                    
                    # Suggestions
                    st.markdown("#### üí° Suggestions to Reduce Risk")
                    if default_prob > 0.3:
                        suggestions = []
                        if int_rate > 12:
                            suggestions.append("‚Ä¢ Consider negotiating a lower interest rate")
                        if dti > 20:
                            suggestions.append("‚Ä¢ Reduce existing debt before applying")
                        if loan_amount > annual_inc * 0.25:
                            suggestions.append("‚Ä¢ Request a smaller loan amount")
                        if home_ownership == "RENT":
                            suggestions.append("‚Ä¢ Building home equity can improve approval odds")
                        
                        for suggestion in suggestions:
                            st.markdown(suggestion)
            else:
                st.warning("‚ö†Ô∏è Please train models in the Modeling tab first to use the predictor.")
        
        with insight_tabs[2]:
            st.markdown("### üìä Portfolio Risk Analysis")
            
            if 'df_processed' in st.session_state:
                df_analysis = df_raw.copy()
                
                # Risk distribution
                st.markdown("#### Risk Distribution by Grade")
                col_risk1, col_risk2 = st.columns(2)
                
                with col_risk1:
                    if 'grade' in df_analysis.columns:
                        fig, ax = plt.subplots(figsize=(8, 5))
                        grade_default = pd.crosstab(df_analysis['grade'], df_analysis['loan_status'], normalize='index')
                        if 'Charged Off' in grade_default.columns:
                            grade_default['Charged Off'].plot(kind='bar', ax=ax, color='#f87171', edgecolor='black')
                            ax.set_xlabel('Grade', fontsize=12)
                            ax.set_ylabel('Default Rate', fontsize=12)
                            ax.set_title('Default Rate by Loan Grade', fontsize=14, fontweight='bold')
                            ax.axhline(y=0.2, color='red', linestyle='--', label='20% Threshold')
                            ax.legend()
                            plt.xticks(rotation=0)
                            st.pyplot(fig)
                            plt.close()
                
                with col_risk2:
                    st.markdown("**Risk Categories:**")
                    if 'grade' in df_analysis.columns:
                        grade_counts = df_analysis['grade'].value_counts()
                        total = len(df_analysis)
                        
                        low_risk = grade_counts[grade_counts.index.isin(['A', 'B'])].sum()
                        med_risk = grade_counts[grade_counts.index.isin(['C', 'D'])].sum()
                        high_risk = grade_counts[grade_counts.index.isin(['E', 'F', 'G'])].sum()
                        
                        st.metric("üü¢ Low Risk (A-B)", f"{low_risk:,}", f"{low_risk/total*100:.1f}%")
                        st.metric("üü° Medium Risk (C-D)", f"{med_risk:,}", f"{med_risk/total*100:.1f}%")
                        st.metric("üî¥ High Risk (E-G)", f"{high_risk:,}", f"{high_risk/total*100:.1f}%")
                        
                        if high_risk/total > 0.2:
                            st.warning("‚ö†Ô∏è High-risk loans exceed 20% of portfolio!")
                        else:
                            st.success("‚úÖ Portfolio risk distribution is healthy")

        
    # TAB 6: Complete Analysis
    with tabs[5]:
        st.header("üìö Complete Case Study Analysis")
        
        # Read the case study content
        try:
            with open("LoanTap Logistic Regression.txt", "r") as f:
                content = f.read()
        except:
            content = "Case study file not found."
        
        # Create styled sections
        st.markdown("""
        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                    padding: 2rem; border-radius: 15px; margin-bottom: 2rem;
                    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);'>
            <h2 style='color: white; margin: 0; border: none;'>üéØ LoanTap Logistic Regression Case Study</h2>
            <p style='color: #e0e7ff; margin-top: 0.5rem; font-size: 1.1rem;'>
                Building an Intelligent Underwriting Layer for Credit Assessment
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Create tabs for different sections
        analysis_tabs = st.tabs([
            "üìã Overview", 
            "üéØ Problem Statement", 
            "üìä Data Dictionary", 
            "üî¨ Methodology", 
            "üìà Results & Insights",
            "üíº Business Recommendations"
        ])
        
        # Tab 1: Overview
        with analysis_tabs[0]:
            st.markdown("""
            <div style='background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; border-left: 4px solid #667eea; margin-bottom: 1rem;'>
                <h3 style='color: #667eea; margin-top: 0;'>üí° Mindset</h3>
                <p style='color: #d1d5db;'>
                    Evaluation will be kept lenient, so make sure you attempt this case study. 
                    It is understandable that you might struggle with getting started on this. 
                    Just brainstorm, discuss with peers, or get help from TAs.
                </p>
                <p style='color: #d1d5db;'>
                    <strong>There is no right or wrong answer.</strong> We have to become comfortable 
                    dealing with uncertainty in business. This is exactly the skill we want to develop.
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("### üè¢ About LoanTap")
            
            col_about1, col_about2 = st.columns(2)
            
            with col_about1:
                st.markdown("""
                <div style='background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); 
                            padding: 1.5rem; border-radius: 15px; height: 100%;
                            box-shadow: 0 4px 15px rgba(17, 153, 142, 0.4);'>
                    <h4 style='color: white; margin-top: 0;'>üöÄ Company Overview</h4>
                    <p style='color: white;'>
                        LoanTap is an online platform committed to delivering <strong>customized loan products to millennials</strong>. 
                        They innovate in an otherwise dull loan segment, to deliver instant, flexible loans on consumer 
                        friendly terms to salaried professionals and businessmen.
                    </p>
                </div>
                """, unsafe_allow_html=True)
            
            with col_about2:
                st.markdown("""
                <div style='background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
                            padding: 1.5rem; border-radius: 15px; height: 100%;
                            box-shadow: 0 4px 15px rgba(240, 147, 251, 0.4);'>
                    <h4 style='color: white; margin-top: 0;'>üéØ Mission</h4>
                    <p style='color: white;'>
                        The data science team at LoanTap is building an <strong>underwriting layer</strong> to determine 
                        the creditworthiness of MSMEs as well as individuals, ensuring responsible lending practices.
                    </p>
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("### üí≥ Financial Products")
            
            products = [
                {"name": "Personal Loan", "icon": "üí∞", "desc": "Flexible personal loans for various needs"},
                {"name": "EMI Free Loan", "icon": "üéÅ", "desc": "No EMI for initial period"},
                {"name": "Personal Overdraft", "icon": "üí≥", "desc": "Credit line for emergencies"},
                {"name": "Advance Salary Loan", "icon": "‚ö°", "desc": "Quick access to salary advance"}
            ]
            
            cols = st.columns(4)
            for idx, product in enumerate(products):
                with cols[idx]:
                    st.markdown(f"""
                    <div style='background: rgba(102, 126, 234, 0.1); padding: 1rem; border-radius: 10px; text-align: center;'>
                        <div style='font-size: 2rem;'>{product['icon']}</div>
                        <h4 style='color: #667eea; margin: 0.5rem 0;'>{product['name']}</h4>
                        <p style='color: #9ca3af; font-size: 0.85rem; margin: 0;'>{product['desc']}</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            st.info("üìå **Focus:** This case study focuses on the underwriting process behind **Personal Loan** only.")
        
        # Tab 2: Problem Statement
        with analysis_tabs[1]:
            st.markdown("""
            <div style='background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); 
                        padding: 2rem; border-radius: 15px; margin-bottom: 2rem;
                        box-shadow: 0 4px 15px rgba(250, 112, 154, 0.4);'>
                <h3 style='color: white; margin-top: 0;'>üéØ Problem Statement</h3>
                <p style='color: white; font-size: 1.1rem;'>
                    Given a set of attributes for an Individual, determine if a credit line should be extended to them. 
                    If so, what should the repayment terms be in business recommendations?
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("### üéØ Key Objectives")
            
            objectives = [
                {"title": "Credit Assessment", "desc": "Determine creditworthiness of loan applicants", "icon": "‚úÖ"},
                {"title": "Risk Mitigation", "desc": "Minimize Non-Performing Assets (NPA)", "icon": "üõ°Ô∏è"},
                {"title": "Optimal Terms", "desc": "Recommend appropriate repayment terms", "icon": "üìä"},
                {"title": "Data-Driven", "desc": "Use ML models for objective decisions", "icon": "ü§ñ"}
            ]
            
            cols = st.columns(2)
            for idx, obj in enumerate(objectives):
                with cols[idx % 2]:
                    st.markdown(f"""
                    <div style='background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem;
                                border-left: 4px solid #667eea;'>
                        <div style='display: flex; align-items: center;'>
                            <span style='font-size: 2rem; margin-right: 1rem;'>{obj['icon']}</span>
                            <div>
                                <h4 style='color: #667eea; margin: 0;'>{obj['title']}</h4>
                                <p style='color: #9ca3af; margin: 0.5rem 0 0 0;'>{obj['desc']}</p>
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
        
        # Tab 3: Data Dictionary
        with analysis_tabs[2]:
            st.markdown("### üìä Dataset Information")
            st.info("**Dataset:** LoanTapData.csv (logistic_regression.txt)")
            
            # Create a nice table for data dictionary
            data_dict = {
                "Feature": [
                    "loan_amnt", "term", "int_rate", "installment", "grade", "sub_grade",
                    "emp_title", "emp_length", "home_ownership", "annual_inc", "verification_status",
                    "issue_d", "loan_status", "purpose", "title", "dti", "earliest_cr_line",
                    "open_acc", "pub_rec", "revol_bal", "revol_util", "total_acc",
                    "initial_list_status", "application_type", "mort_acc", "pub_rec_bankruptcies", "Address"
                ],
                "Description": [
                    "Listed loan amount applied for",
                    "Number of payments (36 or 60 months)",
                    "Interest rate on the loan",
                    "Monthly payment amount",
                    "LoanTap assigned loan grade",
                    "LoanTap assigned loan subgrade",
                    "Job title of borrower",
                    "Employment length (0-10 years)",
                    "Home ownership status",
                    "Self-reported annual income",
                    "Income verification status",
                    "Month loan was funded",
                    "Current loan status (TARGET)",
                    "Loan purpose category",
                    "Loan title provided by borrower",
                    "Debt-to-income ratio",
                    "Earliest credit line date",
                    "Number of open credit lines",
                    "Number of derogatory public records",
                    "Total credit revolving balance",
                    "Revolving line utilization rate",
                    "Total number of credit lines",
                    "Initial listing status (W/F)",
                    "Individual or joint application",
                    "Number of mortgage accounts",
                    "Number of public bankruptcies",
                    "Address of individual"
                ],
                "Type": [
                    "Numerical", "Categorical", "Numerical", "Numerical", "Categorical", "Categorical",
                    "Categorical", "Numerical", "Categorical", "Numerical", "Categorical",
                    "Date", "Categorical", "Categorical", "Text", "Numerical", "Date",
                    "Numerical", "Numerical", "Numerical", "Numerical", "Numerical",
                    "Categorical", "Categorical", "Numerical", "Numerical", "Text"
                ]
            }
            
            df_dict = pd.DataFrame(data_dict)
            
            # Add search functionality
            search_feature = st.text_input("üîç Search for a feature", placeholder="e.g., loan_amnt, grade, dti")
            
            if search_feature:
                filtered_dict = df_dict[df_dict['Feature'].str.contains(search_feature, case=False, na=False)]
                st.dataframe(filtered_dict, use_container_width=True, height=400)
            else:
                st.dataframe(df_dict, use_container_width=True, height=600)
            
            # Feature categories
            st.markdown("### üìë Feature Categories")
            col_cat1, col_cat2, col_cat3 = st.columns(3)
            
            with col_cat1:
                st.markdown("""
                **üí∞ Loan Information**
                - loan_amnt
                - term
                - int_rate
                - installment
                - grade/sub_grade
                """)
            
            with col_cat2:
                st.markdown("""
                **üë§ Borrower Profile**
                - emp_title/emp_length
                - home_ownership
                - annual_inc
                - verification_status
                - Address
                """)
            
            with col_cat3:
                st.markdown("""
                **üìä Credit History**
                - earliest_cr_line
                - open_acc
                - pub_rec
                - revol_bal/revol_util
                - mort_acc
                """)
        
        # Tab 4: Methodology
        with analysis_tabs[3]:
            st.markdown("### üî¨ Analysis Methodology")
            
            methodology_steps = [
                {
                    "step": "1", "title": "Exploratory Data Analysis",
                    "desc": "Check structure, characteristics, and target variable dependencies",
                    "icon": "üîç", "color": "#667eea"
                },
                {
                    "step": "2", "title": "Feature Engineering",
                    "desc": "Create flags, handle missing values, and scale features",
                    "icon": "üîß", "color": "#f472b6"
                },
                {
                    "step": "3", "title": "Model Building",
                    "desc": "Logistic Regression, Decision Tree, Random Forest, GBDT, XGBoost",
                    "icon": "ü§ñ", "color": "#11998e"
                },
                {
                    "step": "4", "title": "Evaluation",
                    "desc": "ROC-AUC, Precision-Recall tradeoff, business metrics",
                    "icon": "üìä", "color": "#fa709a"
                },
                {
                    "step": "5", "title": "Recommendations",
                    "desc": "Business insights and deployment strategies",
                    "icon": "üí°", "color": "#fee140"
                }
            ]
            
            for method in methodology_steps:
                st.markdown(f"""
                <div style='background: linear-gradient(135deg, {method['color']}22 0%, {method['color']}11 100%); 
                            padding: 1.5rem; border-radius: 15px; margin-bottom: 1.5rem;
                            border-left: 5px solid {method['color']};'>
                    <div style='display: flex; align-items: center; margin-bottom: 0.5rem;'>
                        <div style='background: {method['color']}; color: white; width: 40px; height: 40px; 
                                    border-radius: 50%; display: flex; align-items: center; justify-content: center;
                                    font-weight: bold; font-size: 1.2rem; margin-right: 1rem;'>
                            {method['step']}
                        </div>
                        <h3 style='color: {method['color']}; margin: 0;'>{method['icon']} {method['title']}</h3>
                    </div>
                    <p style='color: #9ca3af; margin-left: 3.5rem;'>{method['desc']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("### üéØ Concepts Used")
            concepts = [
                "Exploratory Data Analysis (EDA)",
                "Feature Engineering",
                "Logistic Regression",
                "Precision vs Recall Tradeoff",
                "ROC-AUC Analysis",
                "Class Imbalance Handling (SMOTE)",
                "Target Encoding",
                "StandardScaler Normalization"
            ]
            
            cols = st.columns(2)
            for idx, concept in enumerate(concepts):
                with cols[idx % 2]:
                    st.markdown(f"""
                    <div style='background: rgba(102, 126, 234, 0.1); padding: 0.75rem 1rem; 
                                border-radius: 8px; margin-bottom: 0.5rem;'>
                        <span style='color: #667eea;'>‚úì</span> <span style='color: #d1d5db;'>{concept}</span>
                    </div>
                    """, unsafe_allow_html=True)
        
        # Tab 5: Results & Insights
        with analysis_tabs[4]:
            st.markdown("### üìà Key Results")
            
            if 'models_trained' in st.session_state and st.session_state['models_trained']:
                # Show actual model results
                st.success("‚úÖ Models have been trained! View detailed results in the Modeling tab.")
                
                # Quick summary
                model_names = list(st.session_state['results'].keys())
                best_model_name = max(
                    model_names,
                    key=lambda x: roc_auc_score(
                        st.session_state['y_test'],
                        st.session_state['results'][x]['prob']
                    )
                )
                
                best_auc = roc_auc_score(
                    st.session_state['y_test'],
                    st.session_state['results'][best_model_name]['prob']
                )
                
                st.markdown(f"""
                <div style='background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); 
                            padding: 2rem; border-radius: 15px; text-align: center;
                            box-shadow: 0 4px 15px rgba(17, 153, 142, 0.4);'>
                    <h2 style='color: white; margin: 0; border: none;'>üèÜ Best Model: {best_model_name}</h2>
                    <p style='color: white; font-size: 2rem; font-weight: bold; margin: 1rem 0;'>
                        ROC AUC: {best_auc:.4f}
                    </p>
                    <p style='color: #e0f2f1; margin: 0;'>Excellent discrimination between Fully Paid and Charged Off loans</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.info("Train models in the Modeling tab to see results here.")
            
            st.markdown("### üîç Key Insights")
            
            insights = [
                {"title": "Loan Grade Impact", "finding": "Grades E, F, G have 30-40% default rates", "action": "Implement stricter approval criteria", "icon": "üìä"},
                {"title": "Home Ownership", "finding": "Renters show 25% higher default rate", "action": "Require additional verification", "icon": "üè†"},
                {"title": "Interest Rates", "finding": "Loans >15% have 2x default probability", "action": "Risk-based pricing strategy", "icon": "üí∞"},
                {"title": "DTI Ratio", "finding": "DTI >25 significantly increases risk", "action": "Set DTI thresholds", "icon": "üìà"}
            ]
            
            for insight in insights:
                col_ins1, col_ins2 = st.columns([3, 2])
                with col_ins1:
                    st.markdown(f"""
                    <div style='background: rgba(102, 126, 234, 0.1); padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem;'>
                        <h4 style='color: #667eea; margin-top: 0;'>{insight['icon']} {insight['title']}</h4>
                        <p style='color: #d1d5db; margin: 0.5rem 0;'><strong>Finding:</strong> {insight['finding']}</p>
                        <p style='color: #9ca3af; margin: 0;'><strong>Action:</strong> {insight['action']}</p>
                    </div>
                    """, unsafe_allow_html=True)
        
        # Tab 6: Business Recommendations
        with analysis_tabs[5]:
            st.markdown("### üíº Business Recommendations")
            
            recommendations = [
                {
                    "category": "Risk-Based Pricing",
                    "icon": "üí∞",
                    "color": "#667eea",
                    "items": [
                        "Charge 2-3% higher interest for Grade D-G loans",
                        "Offer 0.5-1% discount for Grade A-B with homeownership",
                        "Dynamic pricing based on DTI and credit history"
                    ]
                },
                {
                    "category": "Approval Criteria",
                    "icon": "‚úÖ",
                    "color": "#11998e",
                    "items": [
                        "Set classification threshold at 0.6 for balanced F1 score",
                        "Implement tiered approval process based on grade",
                        "Require co-signer for high-risk applicants"
                    ]
                },
                {
                    "category": "Verification Process",
                    "icon": "üîç",
                    "color": "#f472b6",
                    "items": [
                        "Enhanced income verification for loans >$25k",
                        "Cross-check employment for Grade C-G applicants",
                        "Additional documentation for renters"
                    ]
                },
                {
                    "category": "Portfolio Management",
                    "icon": "üìä",
                    "color": "#fa709a",
                    "items": [
                        "Limit Grade F-G loans to <15% of portfolio",
                        "Maintain 60%+ Grade A-C loans for stability",
                        "Monthly monitoring of DTI distribution"
                    ]
                }
            ]
            
            for rec in recommendations:
                st.markdown(f"""
                <div style='background: linear-gradient(135deg, {rec['color']}22 0%, {rec['color']}11 100%); 
                            padding: 1.5rem; border-radius: 15px; margin-bottom: 1.5rem;
                            border-left: 5px solid {rec['color']};'>
                    <h3 style='color: {rec['color']}; margin-top: 0;'>{rec['icon']} {rec['category']}</h3>
                    <ul style='color: #d1d5db; margin: 0;'>
                """, unsafe_allow_html=True)
                
                for item in rec['items']:
                    st.markdown(f"- {item}")
                
                st.markdown("</ul></div>", unsafe_allow_html=True)
            
            st.markdown("### üéØ Expected Outcomes")
            
            col_out1, col_out2, col_out3 = st.columns(3)
            
            with col_out1:
                st.markdown("""
                <div style='background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); 
                            padding: 1.5rem; border-radius: 15px; text-align: center;
                            box-shadow: 0 4px 15px rgba(17, 153, 142, 0.4);'>
                    <h2 style='color: white; margin: 0; border: none; font-size: 2.5rem;'>15-20%</h2>
                    <p style='color: white; margin: 0.5rem 0 0 0;'>Reduction in NPA</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col_out2:
                st.markdown("""
                <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                            padding: 1.5rem; border-radius: 15px; text-align: center;
                            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);'>
                    <h2 style='color: white; margin: 0; border: none; font-size: 2.5rem;'>25-30%</h2>
                    <p style='color: white; margin: 0.5rem 0 0 0;'>Improved Approval Rate</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col_out3:
                st.markdown("""
                <div style='background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); 
                            padding: 1.5rem; border-radius: 15px; text-align: center;
                            box-shadow: 0 4px 15px rgba(240, 147, 251, 0.4);'>
                    <h2 style='color: white; margin: 0; border: none; font-size: 2.5rem;'>$2-3M</h2>
                    <p style='color: white; margin: 0.5rem 0 0 0;'>Annual Savings</p>
                </div>
                """, unsafe_allow_html=True)

    # TAB 7: Logs
    with tabs[6]:
        st.header("üìù Application Logs")
        try:
            with open("app.log", "r") as f:
                st.text_area("Log Output", f.read(), height=400)
        except:
            st.info("No logs found yet.")


else:
    st.error("Failed to load data. Please check if 'logistic_regression.txt' exists.")
